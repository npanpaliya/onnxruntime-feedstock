{% set name = "onnxruntime" %}
{% set version = "1.7.2" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  - url: https://github.com/microsoft/onnxruntime/archive/refs/tags/v1.7.2.tar.gz
    sha256: ef0135c49922d854b2d1ccac3759d7baf895df537c5f15386ce49fe2430ac688
    patches:
      - 0001-Use-more-system-libraries.patch
      - 0001-Fixed-build-with-gcc-7.patch
  - url: https://github.com/onnx/onnx/archive/971632833036c576cf95499291f689f8bb3519e1.zip
    sha256: 340999131688d6ab7a7939df587057cc9e49d326fc112ff65b58e121a0afad92
    folder: onnx
  - url: https://gitlab.com/libeigen/eigen/-/archive/d10b27fe37736d2944630ecd7557cefa95cf87c9/eigen-d10b27fe37736d2944630ecd7557cefa95cf87c9.tar.gz
    sha256: a3c10a8c14f55e9f09f98b0a0ac6874c21bda91f65b7469d9b1f6925990e867b
    folder: eigen
  - url: https://github.com/NVlabs/cub/archive/c3cceac115c072fb63df1836ff46d8c60d9eb304.zip
    sha256: 8894c68d7549681591c34078dcd40cf34459b6c7d33407f07e2145d2adb683ee 
    folder: cub
  - url: https://github.com/onnx/onnx-tensorrt/archive/3e1264751bc4256f648cda4da74a3d190a5dd3c2.zip
    sha256: b92f7cfbfe743dbbf926fe0ee353b4d2d62a5047cd3a749b637d10f4231cc015
    folder: onnx-tensorrt

build:
  number: 1
  string: h{{ PKG_HASH }}_{{ build_type }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }}   #[build_type == 'cpu']
  string: h{{ PKG_HASH }}_{{ build_type }}{{ cudatoolkit | replace(".*", "") }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }} #[build_type == 'cuda']
  {% if build_type == 'cuda' %}
  script_env:
    - CUDA_HOME
  {% endif %}

requirements:
  build:
    - python {{ python }}                    # [build_platform != target_platform]
#    - cross-python_{{ target_platform }}     # [build_platform != target_platform]
    - numpy {{ numpy }}                      # [build_platform != target_platform]
    - pybind11                               # [build_platform != target_platform]
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - cmake {{ cmake }}
    - ninja {{ ninja }}
    - libprotobuf
    # Use pins to control cos6/cos7 match
    - libgcc-ng  {{ libgcc }}
    - libstdcxx-ng  {{ libstdcxx }}
  host:
    - python {{ python }}
    - pip
    - wheel
    - boost_mp11 {{ boost_mp11 }}
    - flake8
    - flatbuffers
    - gmock {{ gmock }}
    - gtest {{ gmock }}
    - libdate {{ libdate }}
    - python-flatbuffers 
    - re2
    - optional-lite {{ optional_lite }}
    - nsync
    - nlohmann_json {{ nlohmann_json }}
    - libprotobuf
    # We need to statically link protobuf until we link against a system libonnx
    # See: https://github.com/conda-forge/onnxruntime-feedstock/issues/5
    - libprotobuf-static
    - numpy {{ numpy }}
    - pybind11
    - safeint {{ safeint }}
    # Use pins to control cos6/cos7 match
    - libgcc-ng  {{ libgcc }}
    - libstdcxx-ng  {{ libstdcxx }}
    {% if build_type == 'cuda' %}
    - cudatoolkit {{ cudatoolkit }}
    - cudnn {{ cudnn }}
    - tensorrt {{ tensorrt }}   #[py<38]
    {% endif %}
  run:
    - python {{ python }}
    - {{ pin_compatible('numpy') }}
    - protobuf
    {% if build_type == 'cuda' %}
    - cudatoolkit {{ cudatoolkit }}
    - cudnn {{ cudnn }}
    - tensorrt {{ tensorrt }}   #[py<38]
    {% endif %}

test:
  imports:
    - onnxruntime
  commands:
    - pip check
  requires:
    - pip

about:
  home: http://onnxruntime.ai/
  summary: cross-platform, high performance ML inferencing and training accelerator
  license: MIT
  license_file:
    - LICENSE
    - cmake/external/onnx/LICENSE
  description: |
    ONNX Runtime is a cross-platform inference and training machine-learning accelerator.
  dev_url: https://github.com/microsoft/onnxruntime/
  doc_url: https://github.com/microsoft/onnxruntime/tree/master/docs

extra:
  recipe-maintainers:
    - open-ce/open-ce-dev-team
